# -*- coding: utf-8 -*-
"""vehicle_ratings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LGcfwoTUWIQvM3fk3WdJUHSP47D-uVmx

## **Imports**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import plotly.express as px

data = pd.read_csv('/content/combine_rating_all_vehicle.csv')
data.head()

data.info()

"""## **Pre Processing**"""

col = 'Model Name'
modelCounts = pd.DataFrame(data[col].value_counts())
modelCounts.reset_index(inplace=True)
modelCounts.columns = ['Model Name', 'Count']
modelCounts.head()

temp = modelCounts.sort_values(by=['Model Name']).reset_index()
temp = temp[list(temp.columns[1:])]
temp.head()

modelRating = pd.DataFrame(data.groupby(['Model Name', 'Type']).mean()).reset_index()
modelRating.head()

df = pd.concat([modelRating, temp], axis=1)
df = df.T.drop_duplicates().T

df['NewType'] = df['Type'].apply(lambda x: x.split('-')[0])
df.drop_duplicates(keep='first', inplace=True)
df.head()

"""## **EDA**"""

fig = px.bar(df.sort_values(by=['Count']), x = 'Model Name', y='Count', title='Count of Vehicles Sold VS Model')
fig.show()

fig = px.bar(df.sort_values(by=['Rating']), x="Model Name", y="Rating", color='Type', barmode='group', title='Avg. Rating of Vehicles Sold VS Type')
fig.show()

fig = px.bar(pd.DataFrame(df['Type'].value_counts()), title='Count of Vehicles Sold VS Type')
fig.show()

fig = px.box(df, x='Type', y = 'Rating', title='BoxPlot of Ratings')
fig.show()

fig = px.histogram(df, x = 'Rating', title='BoxPlot of Ratings')
fig.show()

"""## **Resampling for Clustering**"""

from sklearn.utils import resample

wheels_2 = df[df['NewType'] == '2']
wheels_4 = df[df['NewType'] == '4']

wheels_2_downsample = resample(wheels_2,
             replace=True,
             n_samples=len(wheels_4),
             random_state=np.random.randint(1, 101))

print(wheels_2_downsample.shape)
print(wheels_4.shape)

D = pd.concat([wheels_2_downsample, wheels_4], axis=0).reset_index()
D = D[list(D)[1:]]
# D.drop_duplicates(keep='first', inplace=True)
D

"""## **Clustering**"""

from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

X = D[['NewType', 'Rating', 'Count']]
X.head()

wcss=[]
r = range(1, 16)
for i in r:
  kmeans = KMeans(i, n_init=1)
  kmeans.fit(X)
  wcss_iter = kmeans.inertia_
  wcss.append(wcss_iter)

number_clusters = r
plt.plot(number_clusters,wcss)
plt.title('The Elbow title')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

"""### **Made 2 Clusters**"""

kmeans = KMeans(n_clusters=2, random_state=np.random.randint(1, 11), n_init="auto").fit(X)

data_with_clusters = D.copy()
identified_clusters = kmeans.fit_predict(X)
data_with_clusters['Clusters'] = identified_clusters

y = 'Count'
fig = px.bar(data_with_clusters.sort_values(by = [y]), x = 'Model Name', y = y, color = 'Clusters', barmode = 'group')
fig.show()

y = 'Rating'
fig = px.bar(data_with_clusters.sort_values(by = [y]), x = 'Model Name', y = y, color = 'Clusters', barmode = 'group')
fig.show()

"""### **Made 3 Clusters**"""

kmeans = KMeans(n_clusters=3, random_state=np.random.randint(1, 11), n_init="auto").fit(X)

data_with_clusters = D.copy()
identified_clusters = kmeans.fit_predict(X)
data_with_clusters['Clusters'] = identified_clusters

y = 'Count'
fig = px.bar(data_with_clusters.sort_values(by = [y]), x = 'Model Name', y = y, color = 'Clusters', barmode = 'group')
fig.show()

y = 'Rating'
fig = px.bar(data_with_clusters.sort_values(by = [y]), x = 'Model Name', y = y, color = 'Clusters', barmode = 'group')
fig.show()

"""## **Conclusion: It works well with Count of Vehicle sold, not Rating**"""